import random, time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
from collections import namedtuple
import matplotlib.pyplot as plt
from collections import OrderedDict


class DQN(nn.Module):

    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(in_features=2, out_features=16)
        self.fc2 = nn.Linear(in_features=16, out_features=32)
        #self.fc3 = nn.Linear(in_features=4, out_features=4)
        #self.fc4 = nn.Linear(in_features=2, out_features=2)
        self.out = nn.Linear(in_features=32, out_features=2)

    def forward(self, input):
        input = F.rrelu(self.fc1(input))
        input = F.rrelu(self.fc2(input))
        #input = F.rrelu(self.fc3(input))
        #input = F.leaky_relu(self.fc4(input))
        output = self.out(input)
        return output

state = OrderedDict([('fc1.weight', torch.tensor([[-0.6342, -0.2151],
        [-0.4452, -0.3912],
        [-0.4958, -0.0844],
        [ 1.0145, -1.5007],
        [-1.2593,  0.9777],
        [ 0.8204, -0.7132]], dtype=torch.float32)), ('fc1.bias', torch.tensor([-1.1556, -0.6621, -0.6177,  0.9942,  0.0428,  0.5206], dtype=torch.float32)), ('out.weight', torch.tensor([[-0.5076, -0.2285, -0.4353,  0.6966, -1.0128,  0.6694],
        [-0.6170, -0.8549, -0.5270,  0.4560, -0.0715,  0.1893]], dtype=torch.float32)), ('out.bias', torch.tensor([0.3969, 0.3958], dtype=torch.float32))])

state1 = OrderedDict([('fc1.weight', torch.tensor([[-0.5715, -0.2471],
        [-0.3853, -0.4578],
        [-0.4237, -0.1018],
        [ 0.9560, -1.5610],
        [-1.4599,  1.1325],
        [ 0.7725, -0.8642]], dtype=torch.float32)), ('fc1.bias', torch.tensor([-1.3711, -0.8749, -0.8328,  1.2052,  0.0651,  0.6952], dtype=torch.float32)), ('out.weight', torch.tensor([[-0.6483, -0.3716, -0.5916,  0.8471, -1.2084,  0.8205],
        [-0.8003, -1.0335, -0.7014,  0.5960, -0.1979,  0.3115]], dtype=torch.float32)), ('out.bias', torch.tensor([0.5195, 0.5940], dtype=torch.float32))])

state2 = OrderedDict([('fc1.weight', torch.tensor([[-0.7569, -0.7710],
        [ 0.0039, -0.7878],
        [ 0.5228, -1.1067],
        [-0.8214, -0.0480],
        [ 0.1364, -0.3679],
        [-0.2647, -0.8022]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 0.0353, -0.6564, -0.9132, -0.0459,  0.6821,  0.0606], dtype=torch.float32)), ('out.weight', torch.tensor([[ 0.3964,  0.1383,  0.4169, -0.4416,  0.6511,  0.3048],
        [-0.0280, -0.6533, -0.7485,  0.2739,  0.4625, -0.1229]], dtype=torch.float32)), ('out.bias', torch.tensor([0.5376, 0.3805], dtype=torch.float32))])

state_good = OrderedDict([('fc1.weight', torch.tensor([[-0.4237, -0.6956],
        [ 0.0238, -0.6871],
        [ 0.5346, -1.0100],
        [-0.7931, -0.1530],
        [ 0.1245, -0.3227],
        [-0.2384, -0.7331]],dtype=torch.float32)), ('fc1.bias', torch.tensor([-0.0373, -0.4785, -0.7803,  0.0905,  0.4848,  0.1132], dtype=torch.float32)), ('out.weight', torch.tensor([[ 0.2464,  0.2429,  0.4995, -0.5276,  0.4947,  0.1821],
        [-0.0529, -0.4651, -0.5701,  0.1449,  0.2621, -0.2300]], dtype=torch.float32)), ('out.bias', torch.tensor([0.3857, 0.1935], dtype=torch.float32))])

state_bad = OrderedDict([('fc1.weight', torch.tensor([[ 0.3193,  0.1503],
        [ 0.4269, -0.2514],
        [ 0.0554,  0.3226],
        [-0.8399, -0.2712],
        [ 0.8163,  0.4787],
        [ 0.1692, -0.3516]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 0.4490,  0.6519, -0.1360,  0.4414, -0.1350, -0.5155], dtype=torch.float32)), ('out.weight', torch.tensor([[-0.1794,  0.2464,  0.1050,  0.3974, -0.3469, -0.2957],
        [ 0.4304, -0.2012, -0.1345,  0.3941,  0.0296, -0.3401]], dtype=torch.float32)), ('out.bias', torch.tensor([-0.0884, -0.2442], dtype=torch.float32))])

state_where_he_jumped_from_the_loop = OrderedDict([('fc1.weight', torch.tensor([[ 0.7504, -1.0923],
        [ 0.0409, -0.4860],
        [-0.2186,  0.8949],
        [-0.8904,  0.4609],
        [-0.5153,  0.1079],
        [ 0.1113,  0.9426]], dtype=torch.float32)), ('fc1.bias', torch.tensor([-0.3363, -0.6107,  0.5352, -0.1487,  0.3520, -0.7957])), ('out.weight', torch.tensor([[-0.0402, -0.6553,  0.2070, -0.5750,  0.0597, -0.8332],
        [-0.5242, -0.7916,  0.6856,  0.3089,  0.5006,  0.4933]], dtype=torch.float32)), ('out.bias', torch.tensor([0.7866, 0.6219], dtype=torch.float32))])

state_w_stutter_at_iter300 = OrderedDict([('fc1.weight', torch.tensor([[ 0.3014,  0.5473],
        [ 0.1154,  0.0905],
        [-0.1134, -0.4225],
        [ 0.3702,  0.1952],
        [ 0.7689, -0.7911],
        [ 0.0382,  0.2713]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 0.8905,  0.7216, -0.7256,  0.3196, -0.6399,  0.3389])), ('out.weight', torch.tensor([[ 0.3198,  0.1396, -0.4705,  0.4890, -0.4831, -0.1168],
        [ 0.5315,  0.1589, -0.5774,  0.3606, -0.6567, -0.0129]], dtype=torch.float32)), ('out.bias', torch.tensor([0.2677, 0.0085], dtype=torch.float32))])

state_after_1000 = OrderedDict([('fc1.weight', torch.tensor([[ 0.2878,  0.6251],
        [ 0.0966,  0.1067],
        [-0.0984, -0.4597],
        [ 0.3515,  0.1164],
        [ 0.7833, -0.8528],
        [ 0.0464,  0.4381]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 1.0864,  0.9448, -0.9197,  0.5199, -0.8321,  0.3783])), ('out.weight', torch.tensor([[ 0.4913,  0.3146, -0.6413,  0.6992, -0.6169,  0.0189],
        [ 0.6957,  0.3285, -0.7462,  0.5201, -0.8449,  0.1472]], dtype=torch.float32)), ('out.bias', torch.tensor([0.4277, 0.1662], dtype=torch.float32))])

state_2l_600 = OrderedDict([('fc1.weight', torch.tensor([[ 0.7346, -0.1583],
        [ 0.3704,  0.3753],
        [ 0.0530, -0.3415],
        [-0.6737,  0.4372],
        [-0.3208, -0.4061],
        [-0.0407, -0.5200]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 0.0629, -0.6272,  0.2965, -0.0907,  0.3007,  0.8406], dtype=torch.float32)), ('fc2.weight', torch.tensor([[-0.4292,  0.2753, -0.0253,  0.0076,  0.0535, -0.3143],
        [ 0.1461,  0.1533,  0.0389,  0.1303,  0.5088,  0.2487],
        [ 0.0550,  0.0783,  0.0185, -0.0455,  0.5142,  0.1521],
        [-0.1101,  0.1191,  0.5316, -0.3524,  0.0621,  0.2506],
        [ 0.0366,  0.3003,  0.2037,  0.4377, -0.2497, -0.0410],
        [-0.1382,  0.4437, -0.5583,  0.5542, -0.3489, -0.1654],
        [ 0.1919, -0.0712,  0.5230, -0.0231,  0.2810,  0.2925],
        [-0.2896,  0.1706,  0.0739, -0.0921, -0.0836,  0.3519],
        [ 0.1043, -0.5864,  0.1592, -0.7286,  0.4083,  0.5549],
        [ 0.1930, -0.0243,  0.1133,  0.0845, -0.0289,  0.3537]], dtype=torch.float32)), ('fc2.bias', torch.tensor([-0.1779,  0.0471,  0.3205, -0.1934,  0.3551, -0.5655, -0.0155,  0.4825,
         0.3561,  0.2291], dtype=torch.float32)), ('out.weight', torch.tensor([[-0.2139,  0.2449,  0.3981,  0.2916, -0.1085, -0.2065,  0.3791,  0.2081,
          0.2297,  0.1357],
        [ 0.2513,  0.2782,  0.3297,  0.1353,  0.3682, -0.0901, -0.1198,  0.3584,
          0.0563,  0.2413]], dtype=torch.float32)), ('out.bias', torch.tensor([-0.0031,  0.2522], dtype=torch.float32))])

state_2l_16_32 = OrderedDict([('fc1.weight', torch.tensor([[ 0.5710,  0.4308],
        [ 0.6649,  0.7621],
        [ 0.5147,  0.7505],
        [-0.4810,  0.3365],
        [-0.4494, -0.2990],
        [-0.1898,  0.3593],
        [-0.5588,  0.4796],
        [ 0.5816, -0.3029],
        [ 0.6563,  0.0406],
        [-0.6656,  0.7889],
        [-0.5067,  0.4797],
        [ 0.5270, -0.6734],
        [ 0.2046,  0.6327],
        [-0.2354,  0.1500],
        [-0.2893, -0.9120],
        [ 0.2724, -0.7329]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 0.3613,  0.9732,  0.1849, -0.5549,  0.2925,  0.3815, -0.9974,  0.8618,
         0.7552,  0.8436,  0.9973, -0.3155,  0.2286, -0.8590,  0.2489,  0.5724], dtype=torch.float32)), ('fc2.weight', torch.tensor([[ 0.2540,  0.5514,  0.4017, -0.2009,  0.2268,  0.2098, -0.4734,  0.1289,
          0.0950,  0.0846,  0.3857, -0.1697,  0.4056, -0.2856,  0.2609,  0.5182],
        [ 0.2640,  0.3861,  0.3502,  0.0035,  0.3994,  0.2824,  0.1651, -0.0183,
          0.0391,  0.1667,  0.2806, -0.2499,  0.1529, -0.2940, -0.0684, -0.1619],
        [ 0.1234,  0.1754, -0.0884,  0.1472,  0.2979,  0.2717, -0.2402,  0.2728,
          0.3367,  0.2685,  0.0081, -0.2877,  0.0366, -0.2945, -0.1064, -0.0684],
        [ 0.3411,  0.3338,  0.1959, -0.2908,  0.2481,  0.4799, -0.3329,  0.2450,
          0.1428,  0.3730,  0.1044, -0.0587,  0.4412, -0.1976,  0.4823,  0.0492],
        [-0.1091, -0.2547, -0.0111,  0.1537, -0.4940, -0.1712,  0.0713, -0.4762,
         -0.4382, -0.5198, -0.0440,  0.2203, -0.2581,  0.0693, -0.3440, -0.4927],
        [ 0.1739,  0.1890, -0.0071, -0.1638,  0.1995,  0.3320, -0.2301,  0.1674,
          0.4054,  0.1466,  0.1921,  0.0538,  0.2651, -0.1502,  0.0911,  0.3385],
        [ 0.1969,  0.2211,  0.3437, -0.4712,  0.1392,  0.5545, -0.2856,  0.1641,
          0.3467,  0.1078,  0.1739, -0.4922,  0.4764, -0.2845,  0.0398,  0.4884],
        [-0.3154, -0.4075, -0.2536,  0.2980, -0.3174, -0.0434,  0.0839, -0.0082,
         -0.1499, -0.1378, -0.3402,  0.4956, -0.1813,  0.0739, -0.1621, -0.3857],
        [-0.1135, -0.1747, -0.2106,  0.2283, -0.0842,  0.0808, -0.1301, -0.1254,
         -0.1549,  0.1187,  0.2514, -0.0665,  0.2654,  0.1062,  0.0954,  0.0167],
        [-0.1410, -0.3074,  0.0315,  0.0825, -0.3250, -0.1734, -0.0832, -0.3751,
         -0.2898, -0.2297, -0.2352,  0.2416, -0.1103,  0.2778, -0.0986, -0.0196],
        [ 0.5178,  0.0808,  0.2158, -0.5086,  0.0526,  0.1833, -0.3959,  0.4121,
          0.1258,  0.2488,  0.2835, -0.2173,  0.1447, -0.2977,  0.2193,  0.0700],
        [ 0.2476,  0.1602,  0.0462, -0.4818,  0.3240,  0.1812, -0.2906,  0.1201,
          0.3561,  0.0387,  0.3600, -0.3503,  0.1714, -0.1310,  0.1551,  0.2923],
        [ 0.1647,  0.3118,  0.0918, -0.2135,  0.3561,  0.3716, -0.2834,  0.0896,
          0.3309,  0.3919,  0.2670, -0.3412,  0.3307, -0.2370,  0.1811,  0.3274],
        [ 0.2158,  0.1512,  0.4752,  0.0047,  0.2101,  0.3634, -0.4127,  0.2810,
          0.3450,  0.3656,  0.3748, -0.0397,  0.4707, -0.1039,  0.4305,  0.4687],
        [ 0.2026,  0.2319,  0.0346, -0.0195,  0.0975,  0.2219, -0.3122,  0.0286,
          0.0882,  0.4492,  0.1183, -0.1294, -0.0410, -0.2010, -0.1292, -0.2016],
        [ 0.1582,  0.3678,  0.4171, -0.1169, -0.0129,  0.2177, -0.0320,  0.0166,
          0.4853,  0.1633,  0.2558,  0.0094, -0.0956, -0.3960,  0.3086,  0.3271],
        [ 0.3281,  0.4431,  0.0234, -0.1485, -0.0425,  0.1199, -0.3282,  0.2049,
          0.1704,  0.0992,  0.3429, -0.2731,  0.3099, -0.4441,  0.3966,  0.0979],
        [-0.1425, -0.1651, -0.1619,  0.1191, -0.2694, -0.2277,  0.4852, -0.5153,
         -0.2243, -0.3792, -0.3521,  0.1423, -0.1599,  0.2079, -0.3429, -0.4027],
        [-0.4057, -0.4971, -0.3884,  0.4806, -0.0353, -0.2890,  0.3928, -0.5191,
         -0.4966, -0.0121, -0.1785, -0.0859, -0.3671,  0.2781, -0.0775, -0.2380],
        [ 0.0610,  0.1305,  0.0235, -0.3204,  0.2435,  0.1609, -0.3370,  0.4198,
          0.1356,  0.3266,  0.4609, -0.0769,  0.1756, -0.0239,  0.2128,  0.3310],
        [-0.2065, -0.3876, -0.4133,  0.3264,  0.1329, -0.1825,  0.0763, -0.1732,
         -0.5324, -0.2390, -0.3098,  0.2317, -0.0165,  0.3362, -0.1666, -0.2579],
        [ 0.4779,  0.0948,  0.3104, -0.0721, -0.0231,  0.1122, -0.3982,  0.3090,
          0.2994,  0.3899,  0.1913, -0.0936,  0.3680, -0.0424,  0.3877,  0.5089],
        [-0.1464, -0.3036, -0.2338,  0.3421,  0.0140, -0.1024,  0.3280, -0.1815,
         -0.3439,  0.1178, -0.1397, -0.0221,  0.1394,  0.1353, -0.3037, -0.0598],
        [ 0.3077,  0.3951,  0.2621, -0.1734,  0.0789,  0.2442, -0.0173,  0.0798,
          0.2352,  0.2991,  0.2833, -0.0966,  0.2844, -0.4528, -0.0217,  0.2283],
        [-0.4545, -0.4155,  0.0517,  0.1903,  0.0026,  0.0031,  0.1841, -0.3032,
         -0.3826, -0.1105, -0.2361,  0.0750, -0.1436,  0.3262,  0.0828, -0.3032],
        [-0.0703, -0.3926, -0.2328,  0.2102, -0.4435, -0.4562,  0.1062, -0.4529,
         -0.2034, -0.5486, -0.3783,  0.3848, -0.0545,  0.2917, -0.4767, -0.4709],
        [ 0.4920,  0.3892,  0.4502, -0.1503,  0.2758,  0.4558, -0.0960,  0.4139,
          0.5579,  0.0610,  0.2637, -0.3788,  0.3909, -0.2817,  0.1311,  0.5414],
        [ 0.3203,  0.3667,  0.2156, -0.1762,  0.1152,  0.0574, -0.3215,  0.1641,
          0.2291,  0.1660,  0.4339, -0.0373,  0.0617, -0.2150,  0.0574,  0.0535],
        [-0.1095,  0.1334, -0.2586, -0.0108, -0.0065,  0.0485,  0.1657, -0.2259,
         -0.2548,  0.2474,  0.0578,  0.0642, -0.2054,  0.1190,  0.2549, -0.2049],
        [ 0.4927,  0.1577,  0.4478, -0.2182,  0.2895,  0.3860, -0.1792,  0.3888,
          0.3685,  0.4045,  0.2846,  0.0061,  0.4108, -0.1140,  0.4037,  0.1867],
        [ 0.4779,  0.4960,  0.4483, -0.2400,  0.3295,  0.0984, -0.3020,  0.1960,
          0.4239,  0.0995,  0.4665, -0.1360,  0.0622, -0.3065,  0.4058,  0.4298],
        [-0.1295, -0.0314,  0.3502,  0.1353, -0.0647,  0.3877,  0.1942,  0.0803,
          0.0656,  0.3075,  0.2698, -0.3770,  0.0631,  0.1824, -0.0285,  0.0173]], dtype=torch.float32)), ('fc2.bias', torch.tensor([ 0.3867,  0.0775,  0.3242,  0.4733, -0.3188,  0.3954,  0.1170, -0.4705,
        -0.0674, -0.1993,  0.2447,  0.4052,  0.3829,  0.4828,  0.1927,  0.1860,
         0.2921, -0.5090, -0.1129,  0.4132, -0.0566,  0.4517, -0.2217,  0.3308,
         0.0787, -0.2003,  0.2287,  0.0787,  0.0697,  0.4248,  0.4552,  0.1275], dtype=torch.float32)), ('out.weight', torch.tensor([[ 0.3574, -0.0462,  0.1153,  0.3313, -0.2527,  0.3312,  0.2687, -0.2012,
         -0.2119, -0.1227,  0.3162,  0.3904,  0.3531,  0.2151, -0.0163,  0.3237,
          0.2501, -0.3062, -0.5145,  0.2161, -0.3102,  0.4490, -0.3074,  0.1965,
         -0.4318, -0.2035,  0.4153,  0.1681, -0.3412,  0.3249,  0.4465, -0.0098],
        [ 0.2832,  0.4217,  0.1340,  0.3408, -0.3866,  0.2282,  0.2698, -0.3683,
          0.0417, -0.3169,  0.1213,  0.3602,  0.4457,  0.2447,  0.4310,  0.0958,
          0.2773, -0.2417, -0.1772,  0.3969, -0.1500,  0.3826, -0.0215,  0.3299,
         -0.0554, -0.3327,  0.2863,  0.2979, -0.0185,  0.2202,  0.3808,  0.1941]], dtype=torch.float32)), ('out.bias', torch.tensor([0.3363, 0.1954], dtype=torch.float32))])

state_2l_16_32_1000iter = OrderedDict([('fc1.weight', torch.tensor([[ 0.6256,  0.5021],
        [ 0.7076,  0.8094],
        [ 0.5489,  0.8840],
        [-0.5293,  0.2930],
        [-0.4113, -0.2496],
        [-0.1493,  0.4083],
        [-0.6045,  0.4355],
        [ 0.6294, -0.2607],
        [ 0.7040,  0.0816],
        [-0.6305,  0.8419],
        [-0.4670,  0.5287],
        [ 0.4944, -0.7110],
        [ 0.2698,  0.7576],
        [-0.2806,  0.1047],
        [-0.2424, -0.9623],
        [ 0.3201, -0.6926]], dtype=torch.float32)), ('fc1.bias', torch.tensor([ 0.4386,  1.0615,  0.2975, -0.6409,  0.3814,  0.4712, -1.0833,  0.9460,
         0.8379,  0.9369,  1.0868, -0.3978,  0.2906, -0.9457,  0.3131,  0.6547], dtype=torch.float32)), ('fc2.weight', torch.tensor([[ 0.3670,  0.6524,  0.5226, -0.2996,  0.2659,  0.2871, -0.5645,  0.2239,
          0.1966,  0.1501,  0.4553, -0.2235,  0.5232, -0.3724,  0.3003,  0.6019],
        [ 0.3042,  0.4371,  0.3902, -0.0446,  0.5309,  0.3593,  0.1118,  0.0329,
          0.0870,  0.2499,  0.3589, -0.3407,  0.2033, -0.3541,  0.0534, -0.1063],
        [ 0.2265,  0.2764,  0.0186,  0.0468,  0.3525,  0.3627, -0.3367,  0.3713,
          0.4379,  0.3505,  0.0927, -0.3614,  0.1465, -0.3893, -0.0541,  0.0237],
        [ 0.4408,  0.4287,  0.3010, -0.3849,  0.2950,  0.5621, -0.4221,  0.3366,
          0.2380,  0.4454,  0.1795, -0.1221,  0.5474, -0.2845,  0.5276,  0.1335],
        [-0.1929, -0.3406, -0.0980,  0.2401, -0.5559, -0.2591,  0.1563, -0.5617,
         -0.5240, -0.6018, -0.1266,  0.2981, -0.3499,  0.1549, -0.4012, -0.5765],
        [ 0.2946,  0.2934,  0.1231, -0.2649,  0.2357,  0.4070, -0.3222,  0.2642,
          0.5104,  0.2092,  0.2594,  0.0039,  0.3894, -0.2370,  0.1282,  0.4221],
        [ 0.3003,  0.3187,  0.4527, -0.5679,  0.1854,  0.6372, -0.3769,  0.2582,
          0.4448,  0.1802,  0.2495, -0.5549,  0.5859, -0.3731,  0.0849,  0.5744],
        [-0.3944, -0.4904, -0.3351,  0.3817, -0.3870, -0.1331,  0.1673, -0.0916,
         -0.2325, -0.2234, -0.4255,  0.5789, -0.2686,  0.1590, -0.2256, -0.4692],
        [-0.1917, -0.1753, -0.3795,  0.2443, -0.0511,  0.1100, -0.1278, -0.1317,
         -0.1687,  0.1521,  0.2793, -0.1105,  0.2448,  0.0975,  0.1128,  0.0141],
        [-0.2124, -0.3852, -0.0413,  0.1611, -0.4114, -0.2653, -0.0030, -0.4543,
         -0.3669, -0.3208, -0.3245,  0.3339, -0.1904,  0.3611, -0.1764, -0.1017],
        [ 0.6714,  0.1936,  0.3895, -0.6146,  0.0788,  0.2478, -0.4880,  0.5115,
          0.2398,  0.2995,  0.3405, -0.2527,  0.2931, -0.3811,  0.2488,  0.1503],
        [ 0.3518,  0.2570,  0.1567, -0.5772,  0.3673,  0.2610, -0.3800,  0.2126,
          0.4533,  0.1079,  0.4325, -0.4094,  0.2814, -0.2174,  0.1976,  0.3759],
        [ 0.2547,  0.4010,  0.1858, -0.3027,  0.4099,  0.4564, -0.3696,  0.1772,
          0.4202,  0.4688,  0.3455, -0.4116,  0.4281, -0.3227,  0.2317,  0.4108],
        [ 0.3134,  0.2461,  0.5773, -0.0898,  0.2613,  0.4491, -0.5032,  0.3735,
          0.4402,  0.4423,  0.4538, -0.1083,  0.5751, -0.1929,  0.4794,  0.5551],
        [ 0.2466,  0.2864,  0.0786, -0.0718,  0.2364,  0.3023, -0.3695,  0.0838,
          0.1399,  0.5357,  0.2000, -0.2237,  0.0131, -0.2649,  0.0015, -0.1414],
        [ 0.3245,  0.4817,  0.6098, -0.2232,  0.0102,  0.2781, -0.1230,  0.1155,
          0.6008,  0.2098,  0.3090, -0.0212,  0.0601, -0.4772,  0.3357,  0.4056],
        [ 0.4266,  0.5382,  0.1267, -0.2431,  0.0072,  0.2045, -0.4184,  0.2973,
          0.2658,  0.1744,  0.4207, -0.3398,  0.4151, -0.5325,  0.4444,  0.1838],
        [-0.2554, -0.2665, -0.2826,  0.2181, -0.3091, -0.3057,  0.5767, -0.6107,
         -0.3262, -0.4456, -0.4225,  0.1971, -0.2777,  0.2952, -0.3827, -0.4869],
        [-0.5637, -0.6077, -0.5704,  0.5845, -0.0586, -0.3492,  0.4820, -0.6159,
         -0.6088, -0.0586, -0.2314, -0.0549, -0.5167,  0.3581, -0.1046, -0.3155],
        [ 0.1388,  0.2124,  0.1036, -0.4030,  0.3138,  0.2504, -0.4195,  0.5022,
          0.2172,  0.4122,  0.5460, -0.1608,  0.2617, -0.1082,  0.2767,  0.4136],
        [-0.3490, -0.4989, -0.5714,  0.4321,  0.1036, -0.2510,  0.1695, -0.2729,
         -0.6447, -0.2938, -0.3706,  0.2717, -0.1576,  0.4217, -0.1986, -0.3401],
        [ 0.5858,  0.1929,  0.4255, -0.1685,  0.0175,  0.1900, -0.4877,  0.4020,
          0.3980,  0.4564,  0.2616, -0.1492,  0.4811, -0.1283,  0.4281,  0.5919],
        [-0.3470, -0.4158, -0.4853,  0.4466, -0.0015, -0.1516,  0.4141, -0.2767,
         -0.4596,  0.0822, -0.1828, -0.0032, -0.0269,  0.2094, -0.3251, -0.1329],
        [ 0.3905,  0.4808,  0.3476, -0.2598,  0.1445,  0.3336, -0.1028,  0.1655,
          0.3208,  0.3834,  0.3678, -0.1771,  0.3752, -0.5392,  0.0386,  0.3131],
        [-0.6461, -0.5263, -0.1861,  0.2935, -0.0137, -0.0471,  0.2696, -0.3976,
         -0.4965, -0.1472, -0.2801,  0.0953, -0.3068,  0.4003,  0.0609, -0.3760],
        [-0.1525, -0.4778, -0.3176,  0.2958, -0.5089, -0.5455,  0.1910, -0.5380,
         -0.2882, -0.6328, -0.4627,  0.4658, -0.1448,  0.3777, -0.5368, -0.5550],
        [ 0.6123,  0.4925,  0.5803, -0.2506,  0.3111,  0.5296, -0.1871,  0.5097,
          0.6620,  0.1224,  0.3297, -0.4273,  0.5145, -0.3674,  0.1675,  0.6241],
        [ 0.4025,  0.4522,  0.3002, -0.2625,  0.1833,  0.1480, -0.4072,  0.2500,
          0.3145,  0.2518,  0.5199, -0.1199,  0.1519, -0.3020,  0.1200,  0.1390],
        [-0.1726,  0.1404, -0.4102,  0.0033,  0.0271,  0.0831,  0.1659, -0.2296,
         -0.2638,  0.2854,  0.0895,  0.0142, -0.2078,  0.1074,  0.2686, -0.2080],
        [ 0.6144,  0.2624,  0.5792, -0.3195,  0.3253,  0.4607, -0.2713,  0.4857,
          0.4738,  0.4667,  0.3515, -0.0433,  0.5358, -0.2007,  0.4405,  0.2702],
        [ 0.5858,  0.5940,  0.5633, -0.3363,  0.3701,  0.1761, -0.3914,  0.2889,
          0.5225,  0.1660,  0.5367, -0.1915,  0.1753, -0.3923,  0.4462,  0.5127],
        [-0.0798,  0.0294,  0.3994,  0.0762,  0.0774,  0.4745,  0.1299,  0.1423,
          0.1238,  0.4008,  0.3584, -0.4792,  0.1228,  0.1115,  0.1078,  0.0851]], dtype=torch.float32)), ('fc2.bias', torch.tensor([ 0.4642,  0.1425,  0.4130,  0.5532, -0.4009,  0.4720,  0.1983, -0.5533,
        -0.0509, -0.2826,  0.3150,  0.4836,  0.4633,  0.5656,  0.2612,  0.2535,
         0.3741, -0.5872, -0.1794,  0.4954, -0.1297,  0.5288, -0.2809,  0.4142,
         0.0193, -0.2833,  0.3041,  0.1631,  0.0891,  0.5012,  0.5323,  0.2033], dtype=torch.float32)), ('out.weight', torch.tensor([[ 0.4288,  0.0190,  0.1817,  0.3959, -0.3132,  0.4000,  0.3466, -0.2667,
         -0.3068, -0.1860,  0.3893,  0.4552,  0.4132,  0.2792,  0.0411,  0.4005,
          0.3210, -0.3661, -0.6079,  0.2721, -0.3914,  0.5197, -0.3973,  0.2679,
         -0.5245, -0.2590,  0.4951,  0.2412, -0.4433,  0.3929,  0.5166,  0.0413],
        [ 0.3471,  0.4907,  0.2043,  0.4082, -0.4548,  0.2945,  0.3337, -0.4353,
          0.0427, -0.3858,  0.1866,  0.4279,  0.5144,  0.3114,  0.5032,  0.1599,
          0.3428, -0.3096, -0.2343,  0.4675, -0.2122,  0.4469, -0.0830,  0.3946,
         -0.1144, -0.4030,  0.3468,  0.3634, -0.0219,  0.2855,  0.4439,  0.2754]], dtype=torch.float32)), ('out.bias', torch.tensor([0.3835, 0.2584], dtype=torch.float32))])

net = DQN()
#net.load_state_dict(state_2l_16_32_1000iter)
net.load_state_dict(torch.load('policy_net'))
net.eval()
list_of_rew_pos = [-0.5, -0.25, 0.0, 0.25, 0.5]
fig, ax = plt.subplots()
greys = ['lightgrey', 'darkgrey', 'grey', 'dimgrey', 'black']
purples = ['mistyrose', 'pink', 'orchid', 'darkviolet', 'navy']

for i, reward_pos in enumerate(list_of_rew_pos):

        arr = np.empty(400, dtype=np.float32)
        arr.fill(reward_pos)
        input = torch.stack((torch.from_numpy(np.linspace(-0.5, 0.5, 400, dtype=np.float32)), torch.from_numpy(arr)), 1)
        output = net(input)

        line1, = ax.plot(output[:, 0].detach().numpy(), label=f'L, {int((reward_pos + 0.5) * 400)}', color=greys[i])
        line2, = ax.plot(output[:, 1].detach().numpy(), label=f'R, {int((reward_pos + 0.5) * 400)}', color=purples[i])

plt.legend(ncol=5, loc='upper center', fontsize=8)
plt.xlabel('position of player in pixels')
plt.ylabel('qvalue')
plt.title('qvalue of the action for player given reward at position')

#plt.show()
fig.savefig("qfuncs.pdf")